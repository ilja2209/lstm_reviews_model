{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Reviews inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nt_J6NKaHia"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "# Подключаем необходимые питонячие библиотеки\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем обученную модель с github.com. Файл представляет собой архив, в котором содержатся файлы хранящие структуру нейронной сети и ее коэффициенты\n",
        "# Для загрузки модели сначала скачаем архив сюда, то есть на сервер, где запущен наш ноутбук. Используем команду wget (см. https://www.gnu.org/software/wget/):\n",
        "!wget https://github.com/ilja2209/lstm_reviews_model/raw/main/lstm_reviews_en.tar.gz"
      ],
      "metadata": {
        "id": "tRVascWFalid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачали. Теперь нужно архив разархивировать:\n",
        "!tar -xvf lstm_reviews_en.tar.gz"
      ],
      "metadata": {
        "id": "o1ly_oBy5hGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаляем архив, ибо он нам уже не нужен и чтобы место на диске нашего сервера не занимал:\n",
        "!rm -f lstm_reviews_en.tar.gz"
      ],
      "metadata": {
        "id": "qnMQSx1e7Bdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Также не забываем скачать предобученный токенайзер, кторый содержит все проиндексированные слова из обучающей выборки. Это нужно для того, чтобы было однозначное соответствие\n",
        "# индексов слов из обучающей выборки и тестовых примеров. Иначе нейронная сеть неправильно отработает\n",
        "# Для загрузки всё также используем wget:\n",
        "!wget https://github.com/ilja2209/lstm_reviews_model/raw/main/tokenizer.pickle"
      ],
      "metadata": {
        "id": "kwSfJZvcBUCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь загружаем наши хранящиеся на диске модель и токенайзер в оперативную память, чтобы с ними дальше можно было работать:"
      ],
      "metadata": {
        "id": "VQ7Qwtb4CR4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем модель:\n",
        "model = keras.models.load_model(\"lstm_reviews_en\")"
      ],
      "metadata": {
        "id": "YiFv2dx0-Jal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем tokenizer:\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "metadata": {
        "id": "Aph2S7_9Clko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вот теперь мы всё приготовили для дальнейшей работы. У нас есть загруженные в память токенайзер и модель. Теперь напишем парочку функций, делающих наш код чище и после этого можем эксперементировать.  "
      ],
      "metadata": {
        "id": "RN6pQuCDC2sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Напишем функцию, на вход которой мы подаем текст, а на выходе получаем вектор, который потом подадим на вход нейронной сети для инференса:\n",
        "def text2Sequence(text):\n",
        "  max_review_len = 100 #Количество слов (чисел, нейронов входного слоя), подаваемых на вход нейронной сети\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  return pad_sequences(sequence, maxlen=max_review_len)\n"
      ],
      "metadata": {
        "id": "j-AbLsLI7JbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Напишем функцию, которая выход нейронной сети преобразует в человеко-читаемый ответ:\n",
        "def result2Text(result):\n",
        "  if result[[0]] < 0.5:\n",
        "    return 'Отзыв отрицательный'\n",
        "  else:\n",
        "    return 'Отзыв положительный'"
      ],
      "metadata": {
        "id": "DdfXdcbX96z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ну вот и всё! С этого места можем эксперементировать с ниференсом. Всё, что описано выше достаточно выполнить один раз, дальше можно просто писать код, который будет подавать на вход модели текст комментария и получать на выходе его тон. Например:"
      ],
      "metadata": {
        "id": "4O9ErhHKEsQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразуем текст в числовое представление\n",
        "seq = text2Sequence('Beautiful young woman turned down a proposal')\n",
        "# Выполняем подаем на вход модели вектор, полученный ранее и сразу же преобразуем результат работы нейронной сети в текстовый результат\n",
        "result = result2Text(model.predict(seq))\n",
        "# Выводим результат на экран\n",
        "print(result)"
      ],
      "metadata": {
        "id": "_3-Mqb4aFak8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "А вот теперь можно попробовать взять список комментариев и, например, посчитать количество положительных и отрицатеельных отзывов. Всё!"
      ],
      "metadata": {
        "id": "fh1Izc_CGX3G"
      }
    }
  ]
}